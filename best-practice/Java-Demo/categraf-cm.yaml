apiVersion: v1
kind: ConfigMap
metadata:
  name: categraf-config
  namespace: flashcat
data:
  config.toml: |
    [global]
    # whether print configs
    print_configs = false
    hostname = ""
    
    # will not add label(agent_hostname) if true
    omit_hostname = false
    
    # global collect interval, unit: second
    interval = 15
    
    # input provider settings; optional: local / http
    providers = ["local","http", "rmq"]
    
    # Setting http.ignore_global_labels = true if disabled report custom labels
    [global.labels]
    # region = "shanghai"
    # env = "localhost"
    
    [global.n9e_server]
    # 将127.0.0.1:17000 替换为n9e的实际地址
    address="http://10.201.0.207:19000"
    # pingmesh探测端口
    pingmesh=[]

    ## Use TLS but skip chain & host verification
    # insecure_skip_verify = true
    # Basic auth username
    basic_auth_user = ""
    # Basic auth password
    basic_auth_pass = ""
    
    [log]
    # file_name is the file to write logs to
    file_name = "stdout"
    
    # options below will not be work when file_name is stdout or stderr
    # max_size is the maximum size in megabytes of the log file before it gets rotated. It defaults to 100 megabytes.
    max_size = 100
    # max_age is the maximum number of days to retain old log files based on the timestamp encoded in their filename.  
    max_age = 1
    # max_backups is the maximum number of old log files to retain.  
    max_backups = 1
    # local_time determines if the time used for formatting the timestamps in backup files is the computer's local time.  
    local_time = true
    # Compress determines if the rotated log files should be compressed using gzip. 
    compress = false
    
    [writer_opt]
    batch = 1000
    chan_size = 1000000
    
    [http]
    enable = false
    address = ":9100"
    print_access = false
    run_mode = "release"
    ignore_hostname = false
    ignore_global_labels = false
    
    [ibex]
    enable = false
    ## ibex flush interval
    interval = "1000ms"
    ## n9e ibex server rpc address
    servers = ["127.0.0.1:20090"]
    ## temp script dir
    meta_dir = "./meta"
    
    
    [prometheus]
    enable = true
    scrape_config_file = "/opt/categraf/cluster-scrape.yaml"
    ## log level, debug warn info error
    log_level = "info"
    
    [udp]
    enable = false
    listen = ":788"
    
    [metrics_v4]
    reportIntervalMs = 2000
    reportPacketSize = 100
